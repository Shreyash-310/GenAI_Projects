{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc839a7",
   "metadata": {},
   "source": [
    "# Install BERT pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5327b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from pytorch-pretrained-bert) (2021.4.4)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from pytorch-pretrained-bert) (1.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from pytorch-pretrained-bert) (1.14.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from pytorch-pretrained-bert) (2.18.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from pytorch-pretrained-bert) (4.60.0)\n",
      "Collecting boto3\n",
      "Note: you may need to restart the kernel to use updated packages.  Downloading boto3-1.17.79-py2.py3-none-any.whl (131 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
      "Collecting s3transfer<0.5.0,>=0.4.0\n",
      "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.21.0,>=1.20.79\n",
      "  Downloading botocore-1.20.79-py2.py3-none-any.whl (7.6 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from botocore<1.21.0,>=1.20.79->boto3->pytorch-pretrained-bert) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.79->boto3->pytorch-pretrained-bert) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\meenakshi.h\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, requests, boto3, pytorch-pretrained-bert\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.22\n",
      "    Uninstalling urllib3-1.22:\n",
      "      Successfully uninstalled urllib3-1.22\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "Successfully installed boto3-1.17.79 botocore-1.20.79 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 requests-2.25.1 s3transfer-0.4.2 urllib3-1.26.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.5.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
      "spacy 3.0.6 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87dd23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 231508/231508 [00:02<00:00, 82211.20B/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82dc47",
   "metadata": {},
   "source": [
    "# get all of the single character tokens by iterating over the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d10894",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_chars = []\n",
    "one_chars_hashes = []\n",
    "\n",
    "# For each token in the vocabulary...\n",
    "for token in tokenizer.vocab.keys():\n",
    "    \n",
    "    # Record any single-character tokens.\n",
    "    if len(token) == 1:\n",
    "        one_chars.append(token)\n",
    "    \n",
    "    # Record single-character tokens preceded by the two hashes.    \n",
    "    elif len(token) == 3 and token[0:2] == '##':\n",
    "        one_chars_hashes.append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d284f9",
   "metadata": {},
   "source": [
    "# Print the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1fa8823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of single character tokens: 997 \n",
      "\n",
      "! \" # $ % & ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; < = > ? @ [ \\ ] ^ _ ` a b\n",
      "c d e f g h i j k l m n o p q r s t u v w x y z { | } ~ ¡ ¢ £ ¤ ¥ ¦ § ¨ © ª « ¬\n",
      "® ° ± ² ³ ´ µ ¶ · ¹ º » ¼ ½ ¾ ¿ × ß æ ð ÷ ø þ đ ħ ı ł ŋ œ ƒ ɐ ɑ ɒ ɔ ɕ ə ɛ ɡ ɣ ɨ\n",
      "ɪ ɫ ɬ ɯ ɲ ɴ ɹ ɾ ʀ ʁ ʂ ʃ ʉ ʊ ʋ ʌ ʎ ʐ ʑ ʒ ʔ ʰ ʲ ʳ ʷ ʸ ʻ ʼ ʾ ʿ ˈ ː ˡ ˢ ˣ ˤ α β γ δ\n",
      "ε ζ η θ ι κ λ μ ν ξ ο π ρ ς σ τ υ φ χ ψ ω а б в г д е ж з и к л м н о п р с т у\n",
      "ф х ц ч ш щ ъ ы ь э ю я ђ є і ј љ њ ћ ӏ ա բ գ դ ե թ ի լ կ հ մ յ ն ո պ ս վ տ ր ւ\n",
      "ք ־ א ב ג ד ה ו ז ח ט י ך כ ל ם מ ן נ ס ע ף פ ץ צ ק ר ש ת ، ء ا ب ة ت ث ج ح خ د\n",
      "ذ ر ز س ش ص ض ط ظ ع غ ـ ف ق ك ل م ن ه و ى ي ٹ پ چ ک گ ں ھ ہ ی ے अ आ उ ए क ख ग च\n",
      "ज ट ड ण त थ द ध न प ब भ म य र ल व श ष स ह ा ि ी ो । ॥ ং অ আ ই উ এ ও ক খ গ চ ছ জ\n",
      "ট ড ণ ত থ দ ধ ন প ব ভ ম য র ল শ ষ স হ া ি ী ে க ச ட த ந ன ப ம ய ர ல ள வ ா ி ு ே\n",
      "ை ನ ರ ಾ ක ය ර ල ව ා ก ง ต ท น พ ม ย ร ล ว ส อ า เ ་ ། ག ང ད ན པ བ མ འ ར ལ ས မ ა\n",
      "ბ გ დ ე ვ თ ი კ ლ მ ნ ო რ ს ტ უ ᄀ ᄂ ᄃ ᄅ ᄆ ᄇ ᄉ ᄊ ᄋ ᄌ ᄎ ᄏ ᄐ ᄑ ᄒ ᅡ ᅢ ᅥ ᅦ ᅧ ᅩ ᅪ ᅭ ᅮ\n",
      "ᅯ ᅲ ᅳ ᅴ ᅵ ᆨ ᆫ ᆯ ᆷ ᆸ ᆼ ᴬ ᴮ ᴰ ᴵ ᴺ ᵀ ᵃ ᵇ ᵈ ᵉ ᵍ ᵏ ᵐ ᵒ ᵖ ᵗ ᵘ ᵢ ᵣ ᵤ ᵥ ᶜ ᶠ ‐ ‑ ‒ – — ―\n",
      "‖ ‘ ’ ‚ “ ” „ † ‡ • … ‰ ′ ″ › ‿ ⁄ ⁰ ⁱ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ⁺ ⁻ ⁿ ₀ ₁ ₂ ₃ ₄ ₅ ₆ ₇ ₈ ₉ ₊ ₍\n",
      "₎ ₐ ₑ ₒ ₓ ₕ ₖ ₗ ₘ ₙ ₚ ₛ ₜ ₤ ₩ € ₱ ₹ ℓ № ℝ ™ ⅓ ⅔ ← ↑ → ↓ ↔ ↦ ⇄ ⇌ ⇒ ∂ ∅ ∆ ∇ ∈ − ∗\n",
      "∘ √ ∞ ∧ ∨ ∩ ∪ ≈ ≡ ≤ ≥ ⊂ ⊆ ⊕ ⊗ ⋅ ─ │ ■ ▪ ● ★ ☆ ☉ ♠ ♣ ♥ ♦ ♭ ♯ ⟨ ⟩ ⱼ ⺩ ⺼ ⽥ 、 。 〈 〉\n",
      "《 》 「 」 『 』 〜 あ い う え お か き く け こ さ し す せ そ た ち っ つ て と な に ぬ ね の は ひ ふ へ ほ ま み\n",
      "む め も や ゆ よ ら り る れ ろ を ん ァ ア ィ イ ウ ェ エ オ カ キ ク ケ コ サ シ ス セ タ チ ッ ツ テ ト ナ ニ ノ ハ\n",
      "ヒ フ ヘ ホ マ ミ ム メ モ ャ ュ ョ ラ リ ル レ ロ ワ ン ・ ー 一 三 上 下 不 世 中 主 久 之 也 事 二 五 井 京 人 亻 仁\n",
      "介 代 仮 伊 会 佐 侍 保 信 健 元 光 八 公 内 出 分 前 劉 力 加 勝 北 区 十 千 南 博 原 口 古 史 司 合 吉 同 名 和 囗 四\n",
      "国 國 土 地 坂 城 堂 場 士 夏 外 大 天 太 夫 奈 女 子 学 宀 宇 安 宗 定 宣 宮 家 宿 寺 將 小 尚 山 岡 島 崎 川 州 巿 帝\n",
      "平 年 幸 广 弘 張 彳 後 御 德 心 忄 志 忠 愛 成 我 戦 戸 手 扌 政 文 新 方 日 明 星 春 昭 智 曲 書 月 有 朝 木 本 李 村\n",
      "東 松 林 森 楊 樹 橋 歌 止 正 武 比 氏 民 水 氵 氷 永 江 沢 河 治 法 海 清 漢 瀬 火 版 犬 王 生 田 男 疒 発 白 的 皇 目\n",
      "相 省 真 石 示 社 神 福 禾 秀 秋 空 立 章 竹 糹 美 義 耳 良 艹 花 英 華 葉 藤 行 街 西 見 訁 語 谷 貝 貴 車 軍 辶 道 郎\n",
      "郡 部 都 里 野 金 鈴 镇 長 門 間 阝 阿 陳 陽 雄 青 面 風 食 香 馬 高 龍 龸 ﬁ ﬂ ！ （ ） ， － ． ／ ： ？ ～\n"
     ]
    }
   ],
   "source": [
    "print('Number of single character tokens:', len(one_chars), '\\n')\n",
    "\n",
    "# Print all of the single characters, 40 per row.\n",
    "\n",
    "# For every batch of 40 tokens...\n",
    "for i in range(0, len(one_chars), 40):\n",
    "    \n",
    "    # Limit the end index so we don't go past the end of the list.\n",
    "    end = min(i + 40, len(one_chars) + 1)\n",
    "    \n",
    "    # Print out the tokens, separated by a space.\n",
    "    print(' '.join(one_chars[i:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09839d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
