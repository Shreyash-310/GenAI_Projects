{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39ac891",
   "metadata": {},
   "source": [
    "# Demo on BERT : case study on sentence classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b1d6c",
   "metadata": {},
   "source": [
    "# Installing the transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca667408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9c951",
   "metadata": {},
   "source": [
    "# Uograding transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b985cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorflow to v2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dddc34",
   "metadata": {},
   "source": [
    "# Import the requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438d8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as tns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ad165",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e957dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\meenakshi.h\\Desktop\\Machine Translation\\Data\\SST2\\train.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebed33",
   "metadata": {},
   "source": [
    " subset of the original dataset is selected for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc1a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb986ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1041\n",
       "0     959\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0995e",
   "metadata": {},
   "source": [
    "# Loading the Pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "687fc561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef97a09f63024bcdba8f10b42832c1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc86540eee8b4fb0a32f082040e4ef65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f3218be3b24f74a80d0235d75ee853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5662f951d67c4dcb826473a3d14ae10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1da0fc1388442fca673f9c8c103975d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (tns.DistilBertModel, tns.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd058377",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef3ba5",
   "metadata": {},
   "source": [
    "# Tokenization<br>\n",
    "tokenize the word suitable for  BERT format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab0e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = data[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c481f5a",
   "metadata": {},
   "source": [
    "# Padding <br>\n",
    "BERT can take the all the tokens at once to process.<br>\n",
    "paddin is used tokeep all list of token to be of same size <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ad302",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd5c544",
   "metadata": {},
   "source": [
    "Print the dimension of the padded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c26828d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3f861",
   "metadata": {},
   "source": [
    "# Masking<br>\n",
    "create an attention mask to make the model to ignore or mask the padding we've added when it's processing its input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6ca91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98f0481",
   "metadata": {},
   "source": [
    "# Model building <br>\n",
    "call a  model() function to run BERT over preprocessed data.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bdc2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509cd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9995dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069ca72",
   "metadata": {},
   "source": [
    "Get the label information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb0adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3a9fc",
   "metadata": {},
   "source": [
    "split our datset into a training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5947ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529790c",
   "metadata": {},
   "source": [
    "train the LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ddfd16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d922b05",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18f4ecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f616e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
