{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bedff0",
   "metadata": {},
   "source": [
    "<font color=blue><b>If you may get compaitable issues with numpy, matplotplib after installing the transformer, please upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3160cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275506e",
   "metadata": {},
   "source": [
    "<font color=blue><b>import pytorch, the pretrained BERT model, and a BERT tokenizer.<br>\n",
    "BERT model is pretrained by Google which has ran for many hours on Wikipedia and Book Corpus, a dataset containing +10,000 books of different genres. <br>\n",
    "transformers provides a number of classes for applying BERT to different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2759af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcd15f7",
   "metadata": {},
   "source": [
    "# <font color=blue><b> Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cddc2",
   "metadata": {},
   "source": [
    "<font color=blue>As BERT is a pretrained model, it expects input data in a specific format: <br>\n",
    "\n",
    " [SEP]- to mark the end of a sentence, or the delimiter between two sentences<br>\n",
    " [CLS]-, indicates the beginning of our text. <br>\n",
    "The Token IDs for the tokens, from BERT's tokenizer<br>\n",
    "Mask IDs to indicate which elements in the sequence are tokens and which are padding elements<br>\n",
    "Segment IDs used to distinguish different sentences<br>\n",
    "Positional Embeddings used to show token position within the sequence<br>\n",
    "\n",
    "Input can be formatted by explicit coding or using the transformer tokenize function. both teh methods are illustrated.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "770c273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Tokens generated from BERT\n",
      "-------------------\n",
      "['[CLS]', 'i', 'will', 'book', 'flight', 'ticket', 'and', 'i', 'will', 'read', 'this', 'book', 'in', 'the', 'flight', 'said', 'david', 'book', '[SEP]']\n",
      "------------------------\n",
      "TOKEN           INDEX\n",
      "------------------------\n",
      "[CLS]           101\n",
      "i             1,045\n",
      "will          2,097\n",
      "book          2,338\n",
      "flight        3,462\n",
      "ticket        7,281\n",
      "and           1,998\n",
      "i             1,045\n",
      "will          2,097\n",
      "read          3,191\n",
      "this          2,023\n",
      "book          2,338\n",
      "in            1,999\n",
      "the           1,996\n",
      "flight        3,462\n",
      "said          2,056\n",
      "david         2,585\n",
      "book          2,338\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "text = \"I will book flight  ticket and I will read this book in the flight said David book\"\n",
    "marker = \"[CLS] \" + text+ \" [SEP]\"\n",
    "\n",
    "# Tokenize the sentence with the BERT tokenizer.\n",
    "tokens= tokenizer.tokenize(marker)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "index = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# Print  the tokens.\n",
    "print('-------------------')\n",
    "print('Tokens generated from BERT')\n",
    "print('-------------------')\n",
    "print (tokens)\n",
    "# Display the words with their indeces.\n",
    "print('------------------------')\n",
    "print('TOKEN           INDEX')\n",
    "print('------------------------')\n",
    "for tup in zip(tokens, index ):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec883b",
   "metadata": {},
   "source": [
    "Below code is an alternate method to tokenize using transformer functions <br>\n",
    " transformers interface provides all the functionalities coded in the above cell using the tokenizer.encode_plus function.<br>\n",
    " user can choose any of the methods to generate ID's for the tokens\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9db0cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1045, 2097, 2338, 3462, 7281, 1998, 1045, 2097, 3191, 2023, 2338, 1999, 1996, 3462, 2056, 2585, 2338], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "data = \"I will book flight  ticket and I will read this book in the flight said David book\"\n",
    "toks = tokenizer.tokenize(data)\n",
    "output = tokenizer.encode_plus(data, add_special_tokens=False)\n",
    "toks_converted = tokenizer.convert_ids_to_tokens(output['input_ids'])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476ce71",
   "metadata": {},
   "source": [
    "# Segment ID\n",
    "<font color=blue>BERT is trained on and expects sentence pairs, using 1s and 0s to distinguish between the two sentences.<br>\n",
    "That is, for each token in \"tokenized_text,\" we must specify which sentence it belongs to: sentence 0 (a series of 0s) or sentence 1 (a series of 1s).<br>\n",
    "For our purposes, single-sentence inputs only require a series of 1s, so we will create a vector of 1s for each token in our input sentence.<br>\n",
    "\n",
    "If you want to process two sentences, assign each word in the first sentence plus the '[SEP]' token a 0, and all tokens of the second sentence a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd33d0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokens)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00718313",
   "metadata": {},
   "source": [
    "# fit BERT model on input text<br>\n",
    "To fit BERT model on the input text , data should be converted to torch tensors because <br>\n",
    "BERT PyTorch interface requires the data  in torch tensors rather than Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23999ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([index ])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True,)\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712c1ab",
   "metadata": {},
   "source": [
    "# Interpretation of above output\n",
    "when < BertModel.from_pretraineding > is called it will fetch the model from the internet which is as shown in above output.<br>\n",
    "model.eval() puts  model in evaluation mode as opposed to training mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47291648",
   "metadata": {},
   "source": [
    "evaluate BERT on given text, and fetch the hidden states of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a140d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de0033",
   "metadata": {},
   "source": [
    "Print the hidden states of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "460a3924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Netwrok hidden states\n",
      "----------------------------------------\n",
      "Number of layers: 13\n",
      "Number of batches: 1\n",
      "Number of tokens: 19\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------')\n",
    "print('Netwrok hidden states')\n",
    "print('----------------------------------------')\n",
    "print (\"Number of layers:\", len(hidden_states), )\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033908b0",
   "metadata": {},
   "source": [
    "# Interpretation of above output\n",
    "<font color=blue>the Hidden state of the netwrok gives 4 dimension as listed below: <br>\n",
    "The layer number (13 layers)  (initial embeddings + 12 BERT layers)<br>\n",
    "The batch number (1 sentence)<br>\n",
    "The word / token number (22 tokens in our sentence)<br>\n",
    "The hidden unit / feature number (768 features)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5720e",
   "metadata": {},
   "source": [
    " let's look at the different instances of the word \"book\" and see whether context is preseved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fcde471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 i\n",
      "2 will\n",
      "3 book\n",
      "4 flight\n",
      "5 ticket\n",
      "6 and\n",
      "7 i\n",
      "8 will\n",
      "9 read\n",
      "10 this\n",
      "11 book\n",
      "12 in\n",
      "13 the\n",
      "14 flight\n",
      "15 said\n",
      "16 david\n",
      "17 book\n",
      "18 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokens):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55608c5b",
   "metadata": {},
   "source": [
    "combine the layers to make this one whole big tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c1a4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 19, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors using `stack` to create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da12587",
   "metadata": {},
   "source": [
    "Current dimensions produced by the model:\n",
    "\n",
    "[# layers, # batches, # tokens, # features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c49a66",
   "metadata": {},
   "source": [
    "remove \"batches\" dimension since we don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e450902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 19, 768])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\".\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa6788",
   "metadata": {},
   "source": [
    "from the above output<br>\n",
    "Current dimensions :\n",
    "\n",
    "[# layers,  # tokens, # features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e780247",
   "metadata": {},
   "source": [
    "Use pytorch Permute function to swap token and layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab741ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 13, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0442e",
   "metadata": {},
   "source": [
    "from the above output<br>\n",
    "Current dimensions :\n",
    "\n",
    "[  # tokens,# layers, # features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e7bcd",
   "metadata": {},
   "source": [
    "Now word or sentence vectors can be generated from hidden states<br>\n",
    "here we will show only word vector creation  from hidden states<br>\n",
    "totally there are 16 tokens and for each token we have to get individual vectors/features<br>\n",
    "13 layers of the model has produced different vectors for each token.<br>\n",
    "so, totally for each token in the input we have 13 separate vectors each of length 768.<br>\n",
    "to get the final word embedding, we sum last 3 vectors from last 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92728947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 19 x 768\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [19 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "\n",
    "    # Sum the vectors from the last 3 layers.\n",
    "    sum_vec = torch.sum(token[-3:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89950cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 i\n",
      "2 will\n",
      "3 book\n",
      "4 flight\n",
      "5 ticket\n",
      "6 and\n",
      "7 i\n",
      "8 will\n",
      "9 read\n",
      "10 this\n",
      "11 book\n",
      "12 in\n",
      "13 the\n",
      "14 flight\n",
      "15 said\n",
      "16 david\n",
      "17 book\n",
      "18 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokens):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64491f6",
   "metadata": {},
   "source": [
    "verification of vectors for the context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92435b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"book\".\n",
      "\n",
      "Read book    tensor([ 0.8234, -1.0166,  3.4270, -1.4349,  2.8383])\n",
      "book the ticket   tensor([ 0.8677,  1.8590,  1.5261, -1.3450,  3.4283])\n",
      "David book    tensor([ 0.2270, -0.0197,  1.1182, -0.0579,  1.6186])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"book\".')\n",
    "print('')\n",
    "print(\"Read book   \", str(token_vecs_sum[3][:5]))\n",
    "print(\"book the ticket  \", str(token_vecs_sum[11][:5]))\n",
    "print(\"David book   \", str(token_vecs_sum[17][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5db0aa",
   "metadata": {},
   "source": [
    "the token book apperas in 3 diffrent places in a sentence with different context.<br>\n",
    "position of book : [3] [11] [17]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe3e54",
   "metadata": {},
   "source": [
    "# cosine similarity between the vectors to make a more precise comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4e696a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.61\n",
      "Vector similarity for *different* meanings:  0.51\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word book \n",
    "# in \"Read book\" vs \"book the ticket\" (different meanings).\n",
    "read_book= 1 - cosine(token_vecs_sum[3], token_vecs_sum[11])\n",
    "book_ticket = 1 - cosine(token_vecs_sum[3], token_vecs_sum[17])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % read_book)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % book_ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f98a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
