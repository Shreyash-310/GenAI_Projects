{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation using LSTM : English to Hindi \n",
    "Problem statement: Collection of sample English words and its equivalent Hindi words are given. <br>\n",
    "The task is to train the machine on these words using LSTM architecture so that, when given an English word, we get the translated Hindi word as output.<br>\n",
    "\n",
    "Dataset:  “English_Hindi.txt” dataset consisting of English and equivalent Hindi words.<br>\n",
    "\n",
    "In this example of model building using LSTM, we need to import the required libraries and need to install TensorFlow before executing the other parts of the code. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing library\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.utils import *\n",
    "from keras.initializers import *\n",
    "import tensorflow as tf\n",
    "import time, random\n",
    "#from keras.optimizers.Adam import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing all required libraries, we need to define the values for all hyperparameters which includes batch size for training, latent dimensionality for the encoding space and also number of samples to train on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "batch_size = 64\n",
    "latent_dim = 256\n",
    "num_samples = 31\n",
    "#31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section of the code, the data vectorization will take place where we will read the input file which contains English sentences and its corresponding French Sentences. In this process, the text sequences are converted into featured vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 31\n",
      "Number of unique input tokens: 38\n",
      "Number of unique output tokens: 51\n",
      "Max sequence length for inputs: 10\n",
      "Max sequence length for outputs: 21\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_chars = set()\n",
    "target_chars = set()\n",
    "\n",
    "with open(r'c:\\Users\\meenakshi.h\\Desktop\\Machine Translation\\Dataset\\English_Hindi.txt', 'r', \n",
    "          encoding='utf-8') as f:lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_chars:\n",
    "            input_chars.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_chars:\n",
    "            target_chars.add(char)\n",
    "\n",
    "input_chars = sorted(list(input_chars))\n",
    "target_chars = sorted(list(target_chars))\n",
    "num_encoder_tokens = len(input_chars)\n",
    "num_decoder_tokens = len(target_chars)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "#Print size\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After featured engineering, we will get the data with all features which will help us to define the input data for encoder and decoder and the target data for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data for encoder and decoder\n",
    "input_token_id = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "target_token_id = dict([(char, i) for i, char in enumerate(target_chars)])\n",
    "\n",
    "encoder_in_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "\n",
    "decoder_in_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_in_data[i, t, input_token_id[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_in_data[i, t, target_token_id[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_id[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section of code, we will define the input sequence for the encoder which has been defined above and process this sequence. At last, we need to set up an initial state for the decoder using ‘encoder_states’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and process the input sequence\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "#We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Using `encoder_states` set up the decoder as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be defining the code for final model which will accepting ‘encoder_inputs’ and ‘decoder_inputs’ as input parameter and ‘decoder_outputs’ as target parameter.\n",
    "\n",
    "After defining the final model, we will be checking it by its summary and data shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 38)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 51)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 302080      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  315392      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 51)     13107       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 630,579\n",
      "Trainable params: 630,579\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_in_data shape: (31, 10, 38)\n",
      "decoder_in_data shape: (31, 21, 51)\n",
      "decoder_target_data shape: (31, 21, 51)\n"
     ]
    }
   ],
   "source": [
    "#Model data Shape\n",
    "print(\"encoder_in_data shape:\",encoder_in_data.shape)\n",
    "print(\"decoder_in_data shape:\",decoder_in_data.shape)\n",
    "print(\"decoder_target_data shape:\",decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are ready with final model, we need to compile and train the model. In this example, the model will be trained in 50 epochs only. But, we can train the model for more number of epochs for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24 samples, validate on 7 samples\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 4s 161ms/step - loss: 1.8498 - val_loss: 2.6762\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8277 - val_loss: 2.6335\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7928 - val_loss: 2.4787\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.6409 - val_loss: 3.0521\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.7716 - val_loss: 2.4580\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.6321 - val_loss: 2.7443\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6121 - val_loss: 2.4538\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.5768 - val_loss: 2.5345\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5224 - val_loss: 2.4949\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5035 - val_loss: 2.5423\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.4960 - val_loss: 2.4488\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.4917 - val_loss: 2.5507\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5021 - val_loss: 2.4512\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.4576 - val_loss: 2.5164\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.4391 - val_loss: 2.4323\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4268 - val_loss: 2.5431\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4141 - val_loss: 2.4503\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.4263 - val_loss: 2.4192\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.3959 - val_loss: 2.6697\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4612 - val_loss: 2.3917\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4056 - val_loss: 2.5291\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3502 - val_loss: 2.4607\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.3824 - val_loss: 2.4179\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.3383 - val_loss: 2.4814\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.3200 - val_loss: 2.4293\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.2843 - val_loss: 2.4296\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.2581 - val_loss: 2.5430\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2729 - val_loss: 2.3454\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.2605 - val_loss: 2.7095\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2943 - val_loss: 2.4144\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.2181 - val_loss: 2.5555\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.2075 - val_loss: 2.4401\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.2621 - val_loss: 2.5158\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.1815 - val_loss: 2.4755\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.2036 - val_loss: 2.4218\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.1707 - val_loss: 2.5133\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1524 - val_loss: 2.3520\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.1290 - val_loss: 2.6881\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.1430 - val_loss: 2.3842\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0928 - val_loss: 2.5662\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0776 - val_loss: 2.3953\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.0923 - val_loss: 2.6034\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.1458 - val_loss: 2.4423\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0761 - val_loss: 2.4465\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.0736 - val_loss: 2.5690\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0831 - val_loss: 2.4523\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.1382 - val_loss: 2.5190\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.0033 - val_loss: 2.4528\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.9920 - val_loss: 2.4464\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 0.9925 - val_loss: 2.6424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b47b7de7b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compiling and training the model\n",
    "import keras\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "#model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss='categorical_crossentropy')\n",
    "\n",
    "model.fit([encoder_in_data, decoder_in_data], decoder_target_data, batch_size = batch_size, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below lines of code, we will define the decode sequence of the text which will be passed to the model as input sequence. The input sequence is encoded into context vector or state vector which will be passed as an input to the decoder with the target sequence. This process will continue to generate the output until the end of the sequence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, char) for char, i in input_token_id.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_id.items())\n",
    "\n",
    "#Define Decode Sequence\n",
    "def decode_sequence(input_seq):\n",
    "    #Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    #Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Get the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_id['\\t']] = 1.\n",
    "\n",
    "    #Sampling loop for a batch of sequences\n",
    "    #(to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        #Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        #Exit condition: either hit max length\n",
    "        #or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        #Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        #Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will validate the model to decode the input words into the target words in this case the model will translate the English words into equivalent Hindi words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: सा््\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: बमसककर\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: छललो.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: छललो.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: छललो.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: नमसककर\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: नमसककर\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: वाा!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: वाा!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: मजे करन।\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: मैं  कक\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: वाह!\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: मज  का।\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: मजेकरर।\n",
      "\n",
      "-\n",
      "Input sentence: Go away!\n",
      "Decoded sentence: मजे कर।\n",
      "\n",
      "-\n",
      "Input sentence: Goodbye!\n",
      "Decoded sentence: म़    ा\n",
      "\n",
      "-\n",
      "Input sentence: Perfect!\n",
      "Decoded sentence: सा्!\n",
      "\n",
      "-\n",
      "Input sentence: Perfect!\n",
      "Decoded sentence: सा्!\n",
      "\n",
      "-\n",
      "Input sentence: Welcome.\n",
      "Decoded sentence: नस््\n",
      "\n",
      "-\n",
      "Input sentence: Welcome.\n",
      "Decoded sentence: नस््\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    input_seq = encoder_in_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
